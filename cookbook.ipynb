{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Data Cookbook: Fundamentals of Web scraping & Data wrangling</h1>\n",
    "<p>\n",
    "Web scraping is an important part of data collection. A lot of the time, useful data won't be readily available to download. With web scraping, we can automate the process of gathering data from multiple web pages, saving us time and effort.\n",
    "\n",
    "By scraping websites, we can access a wide range of data, including text, images, tables, and more. This data can be used for various purposes, such as market research, sentiment analysis, price comparison, content aggregation, and data analysis.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A basic website is set up for demo.<br>\n",
    "run `python app.py` to start server before proceeding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Basic web requests</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p>The libraries **requests** and **BeautifulSoup** are commonly used in Python for web scraping and web content retrieval tasks. \n",
    "\n",
    "requests: It is a powerful library that allows you to send HTTP requests to web pages and web services. With requests, you can easily retrieve HTML content, make GET and POST requests, handle cookies and sessions, and interact with web APIs. It's an essential tool for fetching web data and interacting with web resources programmatically.\n",
    "\n",
    "BeautifulSoup: This library is a popular choice for parsing and navigating HTML and XML documents. It provides a convenient way to extract specific data from web pages by traversing the HTML document's structure. You can search for tags, access tag attributes, and extract text or data of interest. When used in combination with requests, BeautifulSoup becomes a powerful tool for web scraping and data extraction.\n",
    "\n",
    "Together, these libraries enable you to access web content, retrieve information, and perform data extraction tasks efficiently.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the most basic usage of request. requests.get() send a GET request to the designated url, and returns the entire site's content as response. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html lang=\"en\">\n",
      "<head>\n",
      "    <meta charset=\"UTF-8\">\n",
      "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
      "    <title>Document</title>\n",
      "</head>\n",
      "<body>\n",
      "    <h3>click link to see tables</h3>\n",
      "    <a href=\"/table1\">table 1</a>\n",
      "    <a href=\"/table2\">table 2</a>\n",
      "    <a href=\"/\">home</a>\n",
      "    <h3>API guide</h3>\n",
      "    <p>access subdomain 'table-data' and 'table2-data' to retrieve data directly</p>\n",
      "    <p>stock image</p>\n",
      "    <img alt=\"stock\" src=\"/static/stock.png\"></img>\n",
      "</body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "url = \"http://127.0.0.1:5000/\"\n",
    "response = requests.get(url)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see an image present on the site: `<img alt=\"stock\" src=\"/static/stock.png\"></img>`. Pulling image is a bit different, since you can't print it out directly. In order to keep the image, you must save it to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Send a GET request to the image URL\n",
    "response = requests.get(url + '/static/stock.png')\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Save the image locally\n",
    "    with open(\"saved_image.png\", \"wb\") as file:\n",
    "        file.write(response.content)\n",
    "        print(\"Image saved successfully.\")\n",
    "else:\n",
    "    print(\"Failed to retrieve the image.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Using APIs</h2>\n",
    "While some sites doesn't provide ways to retrieve data, requiring you to scrape data off the site directly, some do offer built in methods of fetching data directly(and various other automation functions) in the form of API. APIs are used in a wide range of applications, from web and mobile app development to cloud services integration, IoT (Internet of Things), and more. They enable developers to leverage existing services and functionality, reducing development time and effort while promoting interoperability and flexibility in software ecosystems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The provide sample site has a simplistic API built in, which allows users to retrieve the data tables in the form of JSON. If you nagivate directly to the links, you'll see a raw JSON table. This is much easier to process compared to extracting the tables from html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Email</th>\n",
       "      <th>Phone Number</th>\n",
       "      <th>Department</th>\n",
       "      <th>Manager</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>John Doe</td>\n",
       "      <td>john.doe@example.com</td>\n",
       "      <td>123-456-7890</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>Jane Wilson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jane Smith</td>\n",
       "      <td>jane.smith@example.com</td>\n",
       "      <td>234-567-8901</td>\n",
       "      <td>Design</td>\n",
       "      <td>Robert Black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mike Johnson</td>\n",
       "      <td>mike.johnson@example.com</td>\n",
       "      <td>345-678-9012</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>Emily Green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sarah Williams</td>\n",
       "      <td>sarah.williams@example.com</td>\n",
       "      <td>456-789-0123</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>Michael Brown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>David Brown</td>\n",
       "      <td>david.brown@example.com</td>\n",
       "      <td>567-890-1234</td>\n",
       "      <td>Product</td>\n",
       "      <td>Lisa White</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Name                       Email  Phone Number    Department  \\\n",
       "0        John Doe        john.doe@example.com  123-456-7890   Engineering   \n",
       "1      Jane Smith      jane.smith@example.com  234-567-8901        Design   \n",
       "2    Mike Johnson    mike.johnson@example.com  345-678-9012     Marketing   \n",
       "3  Sarah Williams  sarah.williams@example.com  456-789-0123  Data Science   \n",
       "4     David Brown     david.brown@example.com  567-890-1234       Product   \n",
       "\n",
       "         Manager  \n",
       "0    Jane Wilson  \n",
       "1   Robert Black  \n",
       "2    Emily Green  \n",
       "3  Michael Brown  \n",
       "4     Lisa White  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# URLs for the APIs\n",
    "url_table_data = url+'table-data'\n",
    "url_table2_data = url+'table2-data'\n",
    "\n",
    "# Making GET requests to the APIs\n",
    "response_table_data = requests.get(url_table_data)\n",
    "response_table2_data = requests.get(url_table2_data)\n",
    "\n",
    "# Assuming the APIs return JSON data, parse the JSON into Python dictionaries\n",
    "table_data = response_table_data.json()\n",
    "table2_data = response_table2_data.json()\n",
    "# Turn the JSON output into a Pandas DataFrame for further analysis\n",
    "table_dp = pd.DataFrame(table_data)\n",
    "table2_dp = pd.DataFrame(table2_data)\n",
    "table_dp.head()\n",
    "table2_dp.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
