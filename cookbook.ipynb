{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Data Cookbook: Fundamentals of Web scraping & Data wrangling</h1>\n",
    "<p>\n",
    "Web scraping is an important part of data collection. A lot of the time, useful data won't be readily available to download. With web scraping, we can automate the process of gathering data from multiple web pages, saving us time and effort.\n",
    "\n",
    "By scraping websites, we can access a wide range of data, including text, images, tables, and more. This data can be used for various purposes, such as market research, sentiment analysis, price comparison, content aggregation, and data analysis.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a simple demonstration of how web scraping works. A basic website containing a table is set up as the target.<br>\n",
    "run `python app.py` to start server before proceeding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p>The libraries **requests** and **BeautifulSoup** are commonly used in Python for web scraping and web content retrieval tasks. \n",
    "\n",
    "requests: It is a powerful library that allows you to send HTTP requests to web pages and web services. With requests, you can easily retrieve HTML content, make GET and POST requests, handle cookies and sessions, and interact with web APIs. It's an essential tool for fetching web data and interacting with web resources programmatically.\n",
    "\n",
    "BeautifulSoup: This library is a popular choice for parsing and navigating HTML and XML documents. It provides a convenient way to extract specific data from web pages by traversing the HTML document's structure. You can search for tags, access tag attributes, and extract text or data of interest. When used in combination with requests, BeautifulSoup becomes a powerful tool for web scraping and data extraction.\n",
    "\n",
    "Together, these libraries enable you to access web content, retrieve information, and perform data extraction tasks efficiently.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the most basic usage of request. requests.get() send a GET request to the designated url, and returns the entire site's content as response. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html lang=\"en\">\n",
      "<head>\n",
      "    <meta charset=\"UTF-8\">\n",
      "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
      "    <title>Document</title>\n",
      "</head>\n",
      "<body>\n",
      "    <h3>click link to see tables</h3>\n",
      "    <a href=\"/table1\">table 1</a>\n",
      "    <a href=\"/table2\">table 2</a>\n",
      "    <a href=\"/\">home</a>\n",
      "    <h3>API guide</h3>\n",
      "    <p>access subdomain 'table-data' and 'table2-data' to retrieve data directly</p>\n",
      "</body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "url = \"http://127.0.0.1:5000/\"\n",
    "response = requests.get(url)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
